{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/TPMLGymGA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Appliqué à [Gym.OpenAI]((https://gym.openai.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la page d'[introduction à Gym](https://github.com/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/TPMLIntroGym.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation de gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outil AUTRE QUE COLAB (pyzo, jupyter lab, .....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym\n",
    "!pip install Box2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GYM\n",
    "import gym\n",
    "import Box2D as b2\n",
    "\n",
    "#Random\n",
    "from random import  randint\n",
    "#\n",
    "from math import exp\n",
    "#for sorting\n",
    "import functools\n",
    "#array\n",
    "import numpy as np\n",
    "\n",
    "#for charts\n",
    "import matplotlib.pyplot as plt\n",
    "#On MAc : \n",
    "#import matplotlib\n",
    "#matplotlib.use(\"MacOSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>Sous colab</font>\n",
    "*Sous colab, l'affichage ne sera pas dynamique.. Il faudra passer soit par un rendu sous forme de plot (matplotlib), soit passer par une vidéo à enregistrer...*\n",
    "\n",
    "***Solution pour affichage statique***<br>\n",
    "*Il vous faut importer, seulement si vous utilisez colab, les packages suivants :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install x11-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GYM\n",
    "import gym\n",
    "import Box2D as b2\n",
    "\n",
    "#Random\n",
    "from random import  randint\n",
    "#\n",
    "from math import exp\n",
    "#for sorting\n",
    "import functools\n",
    "#array\n",
    "import numpy as np\n",
    "\n",
    "#for charts\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Charger l' environnement\n",
    "On utilise ici l'environnement `LunarLander-v2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Les valeurs des caractéristiques\n",
    "Pour `LunarLander-v2`, vous trouverez l'explication des valeurs [ici](https://gym.openai.com/envs/LunarLander-v2/).\n",
    "\n",
    "Il s'agit de faire atterrir une sonde sur une planète.\n",
    "\n",
    "L'espace des actions est une valeur discrète dans l'intervalle [0,3] : \n",
    "  - 0 : Ne rien faire\n",
    "  - 1 : allumage du moteur gauche\n",
    "  - 2 : allumage du moteur central\n",
    "  - 3 : allumage du moteur droit\n",
    "\n",
    "Les observations sont au nombre de 8 : \n",
    "  - obs[0] : coordonnée horizontale\n",
    "  - obs[1] : coordonnée verticale\n",
    "  - obs[2] : vitesse horizontale\n",
    "  - obs[3] : vitesse verticale\n",
    "  - obs[4] : angle de la sonde\n",
    "  - obs[5] : vitesse angulaire (de rotation)\n",
    "  - obs[6] : 1 si le pied gauche de la sonde est au contact du sol, 0 sinon\n",
    "  - obs[7] : 1 si le pied droit de la sonde est au contact du sol, 0 sinon\n",
    "\n",
    "Le but est donc de faire atterrir la sonde dans une position donnée (0,0) avec une vitesse suffisamment faible pour éviter le crash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvSpec(LunarLander-v2)\n",
      "nombre et type d'actions =  Discrete(4)\n",
      "nombre et type d'observations =  Box(-inf, inf, (8,), float32)\n",
      "valeurs de  observations les plus basses =  [-inf -inf -inf -inf -inf -inf -inf -inf]\n",
      "valeurs de observations les plus elevées =  [inf inf inf inf inf inf inf inf]\n"
     ]
    }
   ],
   "source": [
    "print(env.spec)\n",
    "print(\"nombre et type d'actions = \", env.action_space) \n",
    "print(\"nombre et type d'observations = \", env.observation_space) \n",
    "print(\"valeurs de  observations les plus basses = \", env.observation_space.low) \n",
    "print(\"valeurs de observations les plus elevées = \", env.observation_space.high) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Re)Initialiser l'environnement\n",
    "`env.reset()` initialise les variables d'environnement. L'exécution est obligatoire après avoir chargé l'environnement. Ici ce sont les coordonnées, l'angle et les vitesses.\n",
    "\n",
    "C'est un environnement non déterministe par défaut, `env.reset()` retourne des valeurs légèrement différentes à chaque exécution : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00223417,  1.4011867 ,  0.22626404, -0.43259206, -0.00258188,\n",
       "       -0.05125214,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme génétique se prète mal aux environnement non stables; aussi nous utiliserons la fonction suivante pour fixer les vitesses et angles initiaux : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    env.reset();\n",
    "    env.lander.angle=0\n",
    "    env.lander.angularVelocity = 0\n",
    "    env.lander.ApplyForceToCenter( (0,0,), False)\n",
    "    env.lander.linearVelocity = b2.b2Vec2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Les actions\n",
    "- Dans `LunarLander-v2` : [-1.0] fait reculer le véhicule d'une force 1, [0] le met au point mort, [1.0] le fait avancer d'une force 1\n",
    "\n",
    "- ***Exécuter une action :***\n",
    "  - *exécution* : `observation, reward,done,info = env.step(action)`\n",
    "    - `observation`: ici les 8 éléments d'observation\n",
    "    - `reward`: utilité de l'état (récompense 100 si bien posé, -100 si crash)\n",
    "    - `done` : booléen (True si but (position) atteinte)\n",
    "    - `info` : éventuelle information retournée par l'outil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemples d'actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_action(no: int, nb: int = 1):\n",
    "    \"\"\"effectue nb fois l'action no dans l'environnement chargé\"\"\"\n",
    "    for _ in range(nb):\n",
    "        env.render()\n",
    "        obs, reward, done, info = env.step(no)\n",
    "        print(obs, reward, done, info)\n",
    "\n",
    "def test():\n",
    "    test_action(0, 40)\n",
    "    test_action(2, 40)\n",
    "    test_action(1, 40)\n",
    "    test_action(3, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset()\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test d'algorithme génétique\n",
    "## Test de programme évolutionnaire pour atteindre l'objectif\n",
    "- Utiliser l'environnement `LunarLander-v2`, car il est plus rapide \n",
    "- Programmez (en python) un algo génétique avec initialement les éléments suivants : \n",
    "  - sequence : tableau de valeurs entières 0, 1, 2 ou 3.\n",
    "  - 1 point de croisement (au centre)\n",
    "    - *(pour commencer, on pourrait proposer 2 points de croisement (au 1/3, et 2/3))*\n",
    "  - taille sequence : taille_seq = 150\n",
    "  - taille population initiale : taille_pop = 500\n",
    "  - taux de gènes mutants dans une séquence : taux_mut_seq = 0.1\n",
    "  - taux de séquences mutantes dans la population : taux_mut_pop = 0.2\n",
    "  - nombre max de cycles de reproductions : nb_cycles = 3000\n",
    "\n",
    "\n",
    "- Pour tester une séquence, il suffit de balayer le tableau et de lancer l'action correspondante..\n",
    "- Les 4 meilleures séquences (11,22,33,44) se reproduisent entre elles, donnant donc 12 fils : 12, 13, 14, 21, 23, 24, 31, 32, 34, 41, 42, 43.\n",
    "- Idéalement, un filtre doit permettre de supprimer les séquences identiques qui pourraient venir des croisements et des mutations.\n",
    "\n",
    "- Tester votre algo sur le nb de générations et afficher le rendu toutes les 100 générations et bien sûr le rendu de la meilleure séquence finale.\n",
    "  - (uniquement la position finale *colab*)\n",
    "  - (sous forme d'animation sous autre outil)\n",
    "\n",
    "\n",
    "- ***NB:*** \n",
    "  - Au plus simple il est possible d'utiliser une population (liste) de couples [sequence, utilite] où l'utilité serait la distance en x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemple :  \n",
    "env.env.state= np.array([-0.5, 0])\n",
    "tab = np.random.randint(-1, 2, 3) \n",
    "couple = [tab, 0]\n",
    "print(couple)\n",
    "for a in couple[0]:\n",
    "    obs, reward, done, info = env.step([a])\n",
    "print(\"arrive en x=\", round(obs[0],2), \", fini=\", done)\n",
    "couple[1] = obs[0]\n",
    "print(\"couple [actions, arrivee] = \", couple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus : \n",
    "- Adapter la récompense pour favoriser les séquences qui atteignent le but en un minimum d'actions utiles (0 étant considéré comme une action inutile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
